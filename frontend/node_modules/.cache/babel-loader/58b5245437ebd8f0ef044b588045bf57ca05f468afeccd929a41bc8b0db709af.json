{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\BEVATEL\\\\desktop\\\\ReactFlow\\\\frontend\\\\src\\\\components\\\\ScrapperNode.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect } from 'react';\nimport { Handle, Position } from 'react-flow-renderer'; //import Ui component\n// import axios from 'axios';//http lib to send request to backend \nimport { useScraper } from './ScraperContext'; //calling useScraper from ScraperContext file\n\n//node component in ui\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nexport const ScrapperNode = () => {\n  _s();\n  const {\n    setScrapedContent\n  } = useScraper();\n  const [url, setUrl] = useState(''); //holding user entered url\n  //The useEffect Hook allows you to perform side effects in your components. (fetchScrapedData)\n  useEffect(() => {\n    const fetchScrapedData = async () => {\n      if (!url) return; //check if url is not empty\n      try {\n        const response = await fetch('http://127.0.0.1:8000/api/scrape/', {\n          //pass url to backend api\n          method: 'POST',\n          headers: {\n            'Content-Type': 'application/json'\n          },\n          body: JSON.stringify({\n            url\n          })\n        });\n        const scrapedData = response.data; //get backend respond\n\n        // console.log('Scrapped Data:', scrapedData);\n        setScrapedContent(scrapedData); //update data that we got from backend\n      } catch (error) {\n        console.error('Error scraping data', error);\n      }\n    };\n    fetchScrapedData(); //calling both fun\n  }, [url, setScrapedContent]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"node webscrapper\",\n    children: [/*#__PURE__*/_jsxDEV(Handle, {\n      type: \"source\",\n      position: Position.Right\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 36,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n      src: require('../image/web.png'),\n      alt: \"Logo\",\n      width: \"30\",\n      height: \"30\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 37,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"input\", {\n      type: \"text\",\n      placeholder: \"Enter URL\",\n      value: url\n      //onChange tracking url update and generate with the new url\n      ,\n      onChange: e => setUrl(e.target.value)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 38,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 35,\n    columnNumber: 5\n  }, this);\n};\n_s(ScrapperNode, \"XevyYix7igoBuRnmWsA0pBpGPd4=\", false, function () {\n  return [useScraper];\n});\n_c = ScrapperNode;\nvar _c;\n$RefreshReg$(_c, \"ScrapperNode\");","map":{"version":3,"names":["React","useState","useEffect","Handle","Position","useScraper","jsxDEV","_jsxDEV","ScrapperNode","_s","setScrapedContent","url","setUrl","fetchScrapedData","response","fetch","method","headers","body","JSON","stringify","scrapedData","data","error","console","className","children","type","position","Right","fileName","_jsxFileName","lineNumber","columnNumber","src","require","alt","width","height","placeholder","value","onChange","e","target","_c","$RefreshReg$"],"sources":["C:/Users/BEVATEL/desktop/ReactFlow/frontend/src/components/ScrapperNode.js"],"sourcesContent":["import React, { useState, useEffect } from 'react';\r\nimport { Handle, Position } from 'react-flow-renderer';//import Ui component\r\n// import axios from 'axios';//http lib to send request to backend \r\nimport { useScraper } from './ScraperContext'; //calling useScraper from ScraperContext file\r\n\r\n//node component in ui\r\nexport const ScrapperNode = () => {\r\n  const { setScrapedContent } = useScraper();\r\n  const [url, setUrl] = useState('');//holding user entered url\r\n//The useEffect Hook allows you to perform side effects in your components. (fetchScrapedData)\r\n  useEffect(() => {\r\n    const fetchScrapedData = async () => {\r\n      if (!url) return;//check if url is not empty\r\n      try {\r\n        const response = await fetch('http://127.0.0.1:8000/api/scrape/', {//pass url to backend api\r\n            method: 'POST',\r\n            headers: {\r\n              'Content-Type': 'application/json'\r\n            },\r\n            body: JSON.stringify({ url })\r\n          });\r\n        const scrapedData = response.data; //get backend respond\r\n        \r\n        // console.log('Scrapped Data:', scrapedData);\r\n        setScrapedContent(scrapedData); //update data that we got from backend\r\n      } catch (error) {\r\n        console.error('Error scraping data', error);\r\n      }\r\n    };\r\n\r\n    fetchScrapedData();//calling both fun\r\n  }, [url, setScrapedContent]);\r\n\r\n  return (\r\n    <div className=\"node webscrapper\">\r\n      <Handle type=\"source\" position={Position.Right} />\r\n      <img src={require('../image/web.png')} alt=\"Logo\" width=\"30\" height=\"30\" />\r\n      <input\r\n        type=\"text\"\r\n        placeholder=\"Enter URL\"\r\n        value={url}\r\n        //onChange tracking url update and generate with the new url\r\n        onChange={(e) => setUrl(e.target.value)}\r\n      />\r\n    </div>\r\n  );\r\n};\r\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAClD,SAASC,MAAM,EAAEC,QAAQ,QAAQ,qBAAqB,CAAC;AACvD;AACA,SAASC,UAAU,QAAQ,kBAAkB,CAAC,CAAC;;AAE/C;AAAA,SAAAC,MAAA,IAAAC,OAAA;AACA,OAAO,MAAMC,YAAY,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAChC,MAAM;IAAEC;EAAkB,CAAC,GAAGL,UAAU,CAAC,CAAC;EAC1C,MAAM,CAACM,GAAG,EAAEC,MAAM,CAAC,GAAGX,QAAQ,CAAC,EAAE,CAAC,CAAC;EACrC;EACEC,SAAS,CAAC,MAAM;IACd,MAAMW,gBAAgB,GAAG,MAAAA,CAAA,KAAY;MACnC,IAAI,CAACF,GAAG,EAAE,OAAO;MACjB,IAAI;QACF,MAAMG,QAAQ,GAAG,MAAMC,KAAK,CAAC,mCAAmC,EAAE;UAAC;UAC/DC,MAAM,EAAE,MAAM;UACdC,OAAO,EAAE;YACP,cAAc,EAAE;UAClB,CAAC;UACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;YAAET;UAAI,CAAC;QAC9B,CAAC,CAAC;QACJ,MAAMU,WAAW,GAAGP,QAAQ,CAACQ,IAAI,CAAC,CAAC;;QAEnC;QACAZ,iBAAiB,CAACW,WAAW,CAAC,CAAC,CAAC;MAClC,CAAC,CAAC,OAAOE,KAAK,EAAE;QACdC,OAAO,CAACD,KAAK,CAAC,qBAAqB,EAAEA,KAAK,CAAC;MAC7C;IACF,CAAC;IAEDV,gBAAgB,CAAC,CAAC,CAAC;EACrB,CAAC,EAAE,CAACF,GAAG,EAAED,iBAAiB,CAAC,CAAC;EAE5B,oBACEH,OAAA;IAAKkB,SAAS,EAAC,kBAAkB;IAAAC,QAAA,gBAC/BnB,OAAA,CAACJ,MAAM;MAACwB,IAAI,EAAC,QAAQ;MAACC,QAAQ,EAAExB,QAAQ,CAACyB;IAAM;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,eAClD1B,OAAA;MAAK2B,GAAG,EAAEC,OAAO,CAAC,kBAAkB,CAAE;MAACC,GAAG,EAAC,MAAM;MAACC,KAAK,EAAC,IAAI;MAACC,MAAM,EAAC;IAAI;MAAAR,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,eAC3E1B,OAAA;MACEoB,IAAI,EAAC,MAAM;MACXY,WAAW,EAAC,WAAW;MACvBC,KAAK,EAAE7B;MACP;MAAA;MACA8B,QAAQ,EAAGC,CAAC,IAAK9B,MAAM,CAAC8B,CAAC,CAACC,MAAM,CAACH,KAAK;IAAE;MAAAV,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACzC,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACC,CAAC;AAEV,CAAC;AAACxB,EAAA,CAxCWD,YAAY;EAAA,QACOH,UAAU;AAAA;AAAAuC,EAAA,GAD7BpC,YAAY;AAAA,IAAAoC,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}